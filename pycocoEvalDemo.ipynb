{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### code from yolov3 repo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anno_json = 'instances_val2017.json'  # annotations json\n",
    "anno_json = 'minimal_2017.json'  # annotations json\n",
    "pred_json = 'yolov3_predictions.json'  # predictions json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.12s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=3.55s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "anno = COCO(anno_json)  # init annotations api\n",
    "pred = anno.loadRes(pred_json)  # init predictions api\n",
    "eval = COCOeval(anno, pred, 'bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=70.58s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=8.79s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.433\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.630\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.284\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.485\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.538\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.346\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.581\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.634\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.474\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.686\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.766\n"
     ]
    }
   ],
   "source": [
    "eval.evaluate()\n",
    "eval.accumulate()\n",
    "eval.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mAP, mAP50 = eval.stats[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4327462989783685\n"
     ]
    }
   ],
   "source": [
    "print(mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.6297499529916971\n"
     ]
    }
   ],
   "source": [
    "print(mAP50)"
   ]
  },
  {
   "source": [
    "### snippet from yolov3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if save_json and len(jdict):\n",
    "#     w = Path(weights[0] if isinstance(weights, list) else weights).stem if weights is not None else ''  # weights\n",
    "#     anno_json = '../coco/annotations/instances_val2017.json'  # annotations json\n",
    "#     pred_json = str(save_dir / f\"{w}_predictions.json\")  # predictions json\n",
    "#     print('\\nEvaluating pycocotools mAP... saving %s...' % pred_json)\n",
    "#     with open(pred_json, 'w') as f:\n",
    "#         json.dump(jdict, f)\n",
    "\n",
    "#     try:  # https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb\n",
    "#         from pycocotools.coco import COCO\n",
    "#         from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "#         anno = COCO(anno_json)  # init annotations api\n",
    "#         pred = anno.loadRes(pred_json)  # init predictions api\n",
    "#         eval = COCOeval(anno, pred, 'bbox')\n",
    "#         if is_coco:\n",
    "#             eval.params.imgIds = [int(Path(x).stem) for x in dataloader.dataset.img_files]  # image IDs to evaluate\n",
    "#         eval.evaluate()\n",
    "#         eval.accumulate()\n",
    "#         eval.summarize()\n",
    "#         map, map50 = eval.stats[:2]  # update results (mAP@0.5:0.95, mAP@0.5)\n",
    "#     except Exception as e:\n",
    "#         print(f'pycocotools unable to run: {e}')"
   ]
  },
  {
   "source": [
    "### Example from pycoco api github"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "# import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running demo for *bbox* results.\n"
     ]
    }
   ],
   "source": [
    "annType = ['segm','bbox','keypoints']\n",
    "annType = annType[1]      #specify type here\n",
    "prefix = 'person_keypoints' if annType=='keypoints' else 'instances'\n",
    "print('Running demo for *%s* results.'%(annType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.31s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annFile='instances_val2017.json'\n",
    "cocoGt=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=4.49s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#initialize COCO detections api\n",
    "resFile='yolov3_predictions.json'\n",
    "cocoDt=cocoGt.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgIds=sorted(cocoGt.getImgIds())\n",
    "imgIds=imgIds[0:100]\n",
    "imgId = imgIds[np.random.randint(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[139, 285, 632, 724, 776, 785, 802, 872, 885, 1000]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "imgIds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.29s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.43s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.540\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.737\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.568\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.368\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.735\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.442\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.670\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.698\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.492\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.712\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.837\n"
     ]
    }
   ],
   "source": [
    "cocoEval = COCOeval(cocoGt,cocoDt,annType)\n",
    "cocoEval.params.imgIds  = imgIds\n",
    "cocoEval.evaluate()\n",
    "cocoEval.accumulate()\n",
    "cocoEval.summarize()"
   ]
  }
 ]
}